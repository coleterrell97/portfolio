{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpu_based_nn",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLIvIBlKPxIafggn1pEKg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coleterrell97/portfolio/blob/master/ML_Practice/gpu_based_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z5sgIl2EmQz"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "EPOCHS = 10"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9oBi4S9FM8T"
      },
      "source": [
        "dataset = MNIST(root=\".\", transform=ToTensor(), download=True)"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VylEVN3FVub"
      },
      "source": [
        "val_size = 10000\n",
        "train_size = 60000-val_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dl = DataLoader(train_set, batch_size = 4096, shuffle=True)\n",
        "val_dl = DataLoader(val_set, batch_size = 1024, shuffle=True)"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uEgqVQgIjU3"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, inputs, hidden_layer, outputs):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_layer = nn.Linear(inputs, hidden_layer)\n",
        "    self.hidden_layer1 = nn.Linear(hidden_layer, 50)\n",
        "    self.hidden_layer2 = nn.Linear(50, outputs)\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    inputs = inputs.view(inputs.size(0), -1)\n",
        "    x = F.relu(self.input_layer(inputs))\n",
        "    x = F.relu(self.hidden_layer1(x))\n",
        "    x = self.hidden_layer2(x)\n",
        "    return x\n",
        "\n",
        "  def fit(self, dl, epochs, loss_fn, optimizer):\n",
        "    for epoch in range(epochs):\n",
        "      loss = None\n",
        "      for xb, labels in dl:\n",
        "        if xb == None:\n",
        "          continue\n",
        "        predictions = model(xb)\n",
        "        loss = loss_fn(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "      print(loss)"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57FzSoCqJUDv"
      },
      "source": [
        "model = Net(784, 200, 10)\n",
        "loss_fn = F.cross_entropy\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLD30VnfRsPl"
      },
      "source": [
        "def get_default_device():\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device(\"cuda\")\n",
        "  else:\n",
        "    return torch.device(\"cpu\")"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQl1CdGxR5yA"
      },
      "source": [
        "device = get_default_device()"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyztytwNSCvS"
      },
      "source": [
        "def to_device(data, device):\n",
        "  if isinstance(data, (list,tuple)):\n",
        "      return [to_device(x, device) for x in data]\n",
        "  return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qsfLjM7TKs-"
      },
      "source": [
        "train_loader = DeviceDataLoader(train_dl, device)\n",
        "val_loader = DeviceDataLoader(val_dl, device)"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8ewnpGKvP4"
      },
      "source": [
        "to_device(model, device)\n",
        "model.fit(train_loader, EPOCHS, loss_fn, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}